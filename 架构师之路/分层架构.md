# Table of Contents

* [1  互联网分层架构的本质](#1--互联网分层架构的本质)
* [2  互联网分层架构之-DAO与服务化](#2--互联网分层架构之-dao与服务化)
  * [2.1 核心问题一：什么时候进行DAO层的抽象](#21-核心问题一：什么时候进行dao层的抽象)
  * [2.2 核心问题二：什么时候要进行数据服务层的抽象](#22-核心问题二：什么时候要进行数据服务层的抽象)
* [3  啊，业务层是否也需要服务化？](#3--啊，业务层是否也需要服务化？)
* [4  互联网分层架构，为啥要前后端分离](#4--互联网分层架构，为啥要前后端分离)
* [5  究竟为什么要引入数据库中间件](#5--究竟为什么要引入数据库中间件)
  * [5.1 partition key上的单行查询](#51-partition-key上的单行查询)
  * [5.2 非patition key上的单行查询](#52-非patition-key上的单行查询)
  * [5.3 patition key上的批量查询](#53-patition-key上的批量查询)
  * [5.4 非patition key上的夸库分页需求](#54-非patition-key上的夸库分页需求)
  * [5.5 其他需求...](#55-其他需求)


# 1  互联网分层架构的本质

![image-20190707182555476](http://ww1.sinaimg.cn/large/006tNc79ly1g4rgli54ovj308m04dt8y.jpg)

上图是一个典型的互联网分层架构：

- **client**：客户端层，典型调用方是browser或者APP
- **web-server**：站点应用层，实现核心业务逻辑，从下游获取数据，对上游返回html或者json
- **cache**：数据-缓存层，加速访问存储
- **db**：数据-数据库层，固化数据存储



如果实施了服务化，中间多了一个服务层，这个分层架构图可能是这样：

![image-20190707182730917](http://ww1.sinaimg.cn/large/006tNc79ly1g4rglizvqyj307g05vaah.jpg)



**同一个层次的内部**，例如端上的APP，以及web-server，也都有进行MVC分层：

- **view层**：展现
- **control层**：逻辑
- **model层**：数据

![image-20190707182924559](http://ww4.sinaimg.cn/large/006tNc79ly1g4rgljgl7oj309p04mt9v.jpg)



可以看到，每个工程师骨子里，都潜移默化的实施着分层架构。

**那么，互联网分层架构的本质究竟是什么呢？**

如果我们仔细思考会发现，不管是跨进程的分层架构，还是进程内的MVC分层，都是一个**“数据移动”**，然后**“被处理”**和**“被呈现”**的过程，归根结底一句话：互联网分层架构，是一个数据移动，处理，呈现的过程，其中**数据移动是整个过程的核心**。

![image-20190707183005890](http://ww1.sinaimg.cn/large/006tNc79ly1g4rglk0zebj309b060t9i.jpg)

如上图所示：

数据处理和呈现要CPU计算，**CPU是固定不动的**：

- db/service/web-server都部署在固定的集群上
- 端上，不管是browser还是APP，也有固定的CPU处理

**数据是移动的**：

- 跨进程移动：数据从数据库和缓存里，转移到service层，到web-server层，到client层
- 同进程移动：数据从model层，转移到control层，转移到view层

![image-20190707183051476](http://ww4.sinaimg.cn/large/006tNc79ly1g4rglkwa56j30cj0660tt.jpg)

数据要移动，所以有两个东西很重要：

- 数据传输的格式
- 数据在各层次的形态

先看**数据传输的格式**，即协议很重要：

- service与db/cache之间，二进制协议/文本协议是数据传输的载体
- web-server与service之间，RPC的二进制协议是数据传输的载体
- client和web-server之间，http协议是数据传输的载体

 

再看**数据在各层次的形态**，以用户数据为例：

- db层，数据是以“行”为单位存在的row(uid, name, age)
- cache层，数据是以kv的形式存在的kv(uid -> User)
- service层，会把row或者kv转化为对程序友好的User对象
- web-server层，会把对程序友好的User对象转化为对http友好的json对象
- client层：最终端上拿到的是json对象

 

**结论：互联网分层架构的本质，是数据的移动。**



# 2  互联网分层架构之-DAO与服务化

## 2.1 核心问题一：什么时候进行DAO层的抽象

![image-20190707185259576](http://ww1.sinaimg.cn/large/006tNc79ly1g4riguywrmj304u02tjrg.jpg)

一个业务系统最初的后端结构如上：

- **web-server层**从db层获取数据并进行加工处理
- **db层**存储数据

**此时，web-server层如何获取底层的数据呢？**

![image-20190707185338995](http://ww2.sinaimg.cn/large/006tNc79ly1g4rigw3ad5j30cg07at9x.jpg)

web-server层获取数据的一段伪代码如上，不用纠结代码的细节，也不用纠结不同编程语言与不同数据库驱动的差异，其获取数据的过程大致为：

- 创建一个与数据库的**连接**，初始化资源
- 根据业务拼装一个**SQL语句**
- 通过连接执行SQL语句，并获得**结果集**
- 通过**游标**遍历结果集，取出每行数据，亦可从每行数据中取出属性数据
- 关闭数据库连接，回收资源

 

如果业务不复杂，这段代码写1次2次还可以，但如果业务越来越复杂，每次都这么获取数据，就略显低效了，有大量冗余、重复、每次必写的代码。

 

**如何让数据的获取更加高效快捷呢？**

![image-20190707185358920](http://ww2.sinaimg.cn/large/006tNc79ly1g4rigwvuthj306l05i74n.jpg)

通过技术手段实现：

- **表**与类的映射
- **属性**与成员的映射
- **SQL**与函数的映射

绝大部分公司正在用的ORM，DAO等技术，就是一种分层抽象，可以提高数据获取的效率，屏蔽连接，游标，结果集这些复杂性。

![image-20190707185414095](http://ww1.sinaimg.cn/large/006tNc79ly1g4rigxxlvmj308103tmxk.jpg)

**结论**

**当**手写代码从DB中获取数据，成为通用痛点的时候，**就**应该抽象出DAO层，简化数据获取过程，提高数据获取效率，向上游屏蔽底层的复杂性。



## 2.2 核心问题二：什么时候要进行数据服务层的抽象

抽象出DAO层之后，系统架构并不会一成不变：

- 随着**业务越来越复杂**，业务系统会不断进行垂直拆分
- 随着**数据量越来越大**，数据库会进行水平切分
- 随着**读并发的越来越大**，会增加缓存降低数据库的压力

 

于是系统架构变成了这个样子：

![image-20190707185551639](http://ww2.sinaimg.cn/large/006tNc79ly1g4rigys8g0j30ge05rq4z.jpg)

**业务系统垂直拆分**，**数据库水平切分**，**缓存**(redis、memcacha）这些都是常见的架构优化手段。



**此时，web-server层如何获取底层的数据呢？**

根据楼主的经验，以用户数据为例，流程一般是这样的：

- **先查缓存**：先用uid尝试从缓存获取数据，如果cache hit，数据获取成功，返回User实体，流程结束
- **确定路由**：如果cache miss，先查询路由配置，确定uid落在哪个数据库实例的哪个库上
- **查询DB**：通过DAO从对应库获取uid对应的数据实体User
- **插入缓存**：将kv(uid, User)放入缓存，以便下次缓存查询数据能够命中缓存

 

如果业务不复杂，这段代码写1次2次还可以，但如果业务越来越复杂，每次都这么获取数据，就略显低效了，有大量冗余、重复、每次必写的代码。

 

特别的，业务垂直拆分成非常多的子系统之后：

- 一旦底层有稍许变化，所有上游的系统都需要升级修改
- 子系统之间很可能出现代码拷贝
- 一旦拷贝代码，出现一个bug，多个子系统都需要升级修改



不相信业务会垂直拆分成多个子系统？举两个例子：

- 58同城有招聘、房产、二手、二手车、黄页等5大头部业务，都需要访问用户数据
- 58到家有月嫂、保姆、丽人、速运、平台等多个业务，也都需要访问用户数据

如果**每个子系统都需要关注缓存，分库，读写分离的复杂性**，调用层会疯掉的。

 

**如何让数据的获取更加高效快捷呢？**

服务化，数据服务层的抽象势在必行。

![image-20190707185827692](http://ww4.sinaimg.cn/large/006tNc79ly1g4rigz6k8gj30af06rta6.jpg)

通过抽象数据服务层：

- **web-server层**可以通过RPC接口，像调用本地函数一样调用远端的数据
- **数据服务层**，只有这一处需要关注缓存，分库，读写分离这些复杂性

![image-20190707185949029](http://ww4.sinaimg.cn/large/006tNc79ly1g4rigzuma8j308t05mdge.jpg)

**结论**

**当**业务越来越复杂，垂直拆分的系统越来越多，数据库实施了水平切分，数据层实施了缓存加速之后，底层数据获取复杂性成为通用痛点的时候，**就**应该抽象出数据服务层，简化数据获取过程，提高数据获取效率，向上游屏蔽底层的复杂性。



# 3  啊，业务层是否也需要服务化？

随着时间的推移，系统架构并不会一成不变：

- 随着业务越来越复杂，**业务会不断进行垂直拆分**
- 随着数据越来越复杂，**基础数据service也会越来越多**

![image-20190707190242362](http://ww4.sinaimg.cn/large/006tNc79ly1g4rih16rakj30h8057dii.jpg)

于是系统架构变成了上图这个样子，业务垂直拆分，有若干个基础数据服务：

- 垂直业务要通过多个RPC接口访问不同的基础数据service，**service共有是服务化的特征**
- 每个基础数据service访问自己的数据存储**，数据私有也是服务化的特征**

 

**这个架构图中的依赖关系是不是看上去很别扭？**

- 基础数据service与存储层之前连接关系很清晰
- 业务web-server层与基础数据service层之间的连接关系错综复杂，变成了蜘蛛网

 

再举一个更具体的例子，58同城**列表页**web-server如何获取底层的数据？

- 首先调用商业基础service，获取商业广告帖子数据，用于顶部置顶/精准的广告帖子展示
- 再调用搜索基础service，获取自然搜索帖子数据，用于中部自然搜索帖子展示
- 再调用推荐基础service，获取推荐帖子数据，用于底部推荐帖子展示
- 再调用用户基础service，获取用户数据，用于右侧用户信息展示
- …

如果只有一个列表页这么写还行，但如果有招聘、房产、二手、二手车、黄页…等多个大部分是共性数据，少部分是个性数据的列表页，每次都这么获取数据，就略显**低效**了，有大量冗余、重复、每次必写的代码。

 

特别的，不同业务上游列表页都依赖于底层若干相同服务：

- 一旦一个服务RPC接口有稍许变化，所有上游的系统都需要升级修改
- 子系统之间很可能出现代码拷贝
- 一旦拷贝代码，出现一个bug，多个子系统都需要升级修改

 

**如何让数据的获取更加高效快捷呢？**

业务服务化，**通用业务服务层**的抽象势在必行。

![image-20190707192412505](http://ww4.sinaimg.cn/large/006tNc79ly1g4rih2360fj30io0770vi.jpg)

通过抽象通用业务服务层，例如58同城“通用列表服务”：

- **web-server层**，可以通过RPC接口，像调用本地函数一样，调用通用业务service，一次性获取所有通用数据
- **通用业务service**，也可以通过多次调用基础数据service提供的RPC接口，分别获取数据，底层数据获取的复杂性，全都屏蔽在了此处 



是不是连接关系也看起来更清晰？



这样的好处是：

- 复杂的从基础服务获取数据代码，只有在通用业务service处写了一次，没有代码拷贝
- 底层基础数据service接口发生变化，只有通用业务service一处需要升级修改
- 如果有bug，不管是底层基础数据service的bug，还是通用业务service的bug，都只有一处需要升级修改
- 业务web-server获取数据更便捷，获取所有数据，只需一个RPC接口调用

![image-20190707192445530](http://ww2.sinaimg.cn/large/006tNc79ly1g4rih2xf92j308r05g3zc.jpg)

**结论**：

**当**业务越来越复杂，垂直拆分的系统越来越多，基础数据服务越来越多，底层数据获取复杂性成为通用痛点的时候，**就**应该抽象出通用业务服务，简化数据获取过程，提高数据获取效率，向上游屏蔽底层的复杂性。



# 4  互联网分层架构，为啥要前后端分离

![image-20190707192814347](http://ww2.sinaimg.cn/large/006tNc79ly1g4rih3d2i0j304q053glz.jpg)

通用业务服务化之后，系统的典型后端结构如上：

- **web-server**通过RPC接口，从通用业务服务获取数据
- **biz-service**通过RPC接口，从多个基础数据service获取数据
- **基础数据service**通过DAO，从独立db/cache获取数据
- **db/cache**存储数据

 

随着时间的推移，系统架构并不会一成不变，业务越来越复杂，改版越来越多，此时web-server层虽然使用了MVC架构，但以下诸多**痛点**是否似曾相识？

- 产品追求绚丽的效果，并对设备兼容性要求高，这些需求不断折磨着使用MVC的Java工程师们（本文以Java举例）
- 不管是PC，还是手机H5，还是APP，应用前端展现的变化频率远远大于后端逻辑的变化频率（感谢那些喜欢做改版的产品经理），改velocity模版并不是Java工程师喜欢和擅长的工作

 

此时，为了缓解这些问题，一般会**成立单独的前端FE部门**，来负责交互与展现的研发，其职责与后端Java工程师分离开，但痛点依然没有完全解决：

- 一点点展现的改动，需要Java工程师们重新编译，打包，上线，重启tomcat，效率极低
- 原先Java工程师负责所有MVC的研发工作，现在分为Java和FE两块，需要等前端和后端都完成研发，才能一起调试整体效果，不仅增加了沟通成本，任何一块出问题，都可能导致项目延期

更具体的，看一个这样的例子，最开始产品**只有PC版本**，此时其系统分层架构如下：

![image-20190707192918674](http://ww4.sinaimg.cn/large/006tNc79ly1g4rih4a6s5j30a804pwf4.jpg)

客户端，web-server，service，非常清晰。

随着业务的发展，**产品需要新增Mobile版本**，Mobile版本和PC版本大部分业务逻辑都一样，唯一的**区别是屏幕比较小**：

- 信息展现的条数会比较少，即调用service服务时，传入的参数会不一样
- 产品功能会比较少，大部分service的调用一样，少数service不需要调用
- 展现，交互会有所区别

 

由于工期较紧，Mobile版本的web-server一般怎么来呢？

![image-20190707192940145](http://ww4.sinaimg.cn/large/006tNc79ly1g4rih5ccncj30at04pmy1.jpg)

没错，**把PC版本的工程拷贝一份，然后再做小量的修改**：

- service调用的参数有些变化
- 大部分service的调用一样，少数service的调用去掉
- 修改展现，交互相关的代码

 

业务继续发展，**产品又需要新增APP版本**，APP版本和Mobile版本业务逻辑完全相同，唯一的区别是：

- Mobile版本返回html格式的数据，APP版本返回json格式的数据，然后进行本地渲染

 

由于工期较紧，APP版本的web-server一般怎么来呢？

![image-20190707192957729](http://ww2.sinaimg.cn/large/006tNc79ly1g4rih67qdaj30bl04rmya.jpg)

没错，**把Mobile版本的工程拷贝一份，然后再做小量的修改**：

- 把拼装html数据的代码，修改为拼装json数据



这么迭代，演化，发展，架构会变成这个样子：

![image-20190707193031418](http://ww2.sinaimg.cn/large/006tNc79ly1g4rih6uawsj30f806l77f.jpg)

- **端**，是PC，Mobile，APP
- **web-server接入**，是PC站，M站，APP站
- **服务层**，通用的业务服务，以及基础数据服务



这个架构图中的依赖关系是不是看上去很别扭？

- 端到web-server之间连接关系很清晰
- web-server与service之间的连接关系变成了蜘蛛网

 

PC/H5/APP的web-server层大部分业务是相同的，只有少数的逻辑/展现/交互不一样：

- 一旦一个服务RPC接口有稍许变化，所有web-server系统都需要升级修改
- web-server之间存在大量代码拷贝
- 一旦拷贝代码，出现一个bug，多个子系统都需要升级修改

 

**如何让数据的获取更加高效快捷，如何让数据生产与数据展现解耦分离呢？**

前后端分离的分层抽象势在必行。

![image-20190707193129441](http://ww1.sinaimg.cn/large/006tNc79ly1g4rih7sotfj30eu0730w8.jpg)

通过前后端分离分层抽象：

- **站点展示层**，node.js，负责数据的展现与交互，由FE维护
- **站点数据层**，web-server，负责业务逻辑与json数据接口的提供，由Java工程师维护

 

这样的好处是：

- 复杂的业务逻辑与数据生成，只有在站点数据层处写了一次，没有代码拷贝
- 底层service接口发生变化，只有站点数据层一处需要升级修改
- 底层service如果有bug，只有站点数据层一处需要升级修改
- 站点展现层可以根据产品的不同形态，传入不同的参数，调用不同的站点数据层接口

 

除此之外：

- 产品追求绚丽的效果，并对设备兼容性要求高，不再困扰Java工程师，由更专业的FE对接
- 一点点展现的改动，不再需要Java工程师们重新编译，打包，上线，重启tomcat
- 约定好json接口后，Java和FE分开开发，FE可以用mock的接口自测，不再等待一起联调

![image-20190707193148027](http://ww1.sinaimg.cn/large/006tNc79ly1g4rih8zk6qj308u06swfk.jpg)

**结论**：

**当**业务越来越复杂，端上的产品越来越多，展现层的变化越来越快越来越多，站点层存在大量代码拷贝，数据获取复杂性成为通用痛点**的时候**，就应该进行前后端分离分层抽象，简化数据获取过程，提高数据获取效率，向上游屏蔽底层的复杂性。



# 5  究竟为什么要引入数据库中间件

随着时间的推移，**数据量会越来越大**，base-service通过DAO来访问db的**性能会越来越低**，**需要开始考虑对db进行水平切分**，一旦db进行水平切分，原来很多SQL可以支持的功能，就需要base-service层来进行特殊处理：

- 有些数据需要路由到特定的水平切分库
- 有些数据不确定落在哪一个水平切分库，就需要访问所有库
- 有些数据需要访问全局的库，拿到数据的全局视野，到service层进行额外处理
- …

 

更具体的，对于前台高并发的业务，db水平切分后，有这么几类典型的业务场景及应对方案。特别强调一下，此处应对的是**“前台”“高并发”“db水平切分”**的场景，对于后台的需求，将通过前台与后台分离的架构处理，不在此处讨论。



## 5.1 partition key上的单行查询

**典型场景**：通过uid查询user



**场景特点**：

- 通过patition key查询
- 每次只返回一行记录



**解决方案**：base-service层通过patition key来进行库路由

![image-20190707200745962](http://ww2.sinaimg.cn/large/006tNc79ly1g4rjgd44yuj309n038wey.jpg)

如上图：

- user-service底层user库，分库patition key是uid
- uid上的查询，user-service可以直接定位到库



## 5.2 非patition key上的单行查询

**典型场景**：通过login_name查询user



**场景特点**：

- 通过非patition key查询
- 每次只返回一行记录



**解决方案1**：base-service层访问所有库

![image-20190707200839721](http://ww1.sinaimg.cn/large/006tNc79ly1g4rjdw84yuj309n038wey.jpg)

如上图：

- user-service通过login_name先查全库
- 结果集在user-service再合并，最终返回一条记录

 

**解决方案2**：base-service先查mapping库，再通过patition key路由

![image-20190707200858505](http://ww3.sinaimg.cn/large/006tNc79ly1g4rjeljkjnj30d503fgmc.jpg)

如上图：

- 新建mapping库，记录login_name到uid的映射关系
- 当有非 patition key的查询时，先通过login_name查询uid
- 再通过patition key进行路由，最终返回一条记录

**解决方案3**：基因法

关于“基因法”解决非patition key上的查询需求详见《[分库后，非patition key上访问的多种解决办法](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651960212&idx=1&sn=ab4c52ab0309f7380f7e0207fa357128&chksm=bd2d06488a5a8f5e3b7c9de0cc5936818bd9a6ed4058679ae8d819175e0693c6fbd9cdea0c87&scene=21#wechat_redirect)》。



## 5.3 patition key上的批量查询

**典型场景**：用户列表uid上的IN查询



**场景特点**：

- 通过patition key查询
- 每次返回多行记录

 

**解决方案1**：base-service层访问所有库，结果集到base-service合并

 

**解决方案2**：base-service分析路由规则，按需访问

![image-20190707201047727](http://ww1.sinaimg.cn/large/006tNc79ly1g4rjfqxwyrj30at04ujs6.jpg)

如上图：

- base-service根据路由规则分析，判断出有些数据落在库1，有些数据落在库2
- base-service按需访问相关库，而不是访问全库
- base-service合并结果集，返回列表数据



## 5.4 非patition key上的夸库分页需求

关于分库后，夸库分页的查询需求，详见《[业界难题，夸库分页的四种方案](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959942&idx=1&sn=e9d3fe111b8a1d44335f798bbb6b9eea&chksm=bd2d075a8a5a8e4cad985b847778aa83056e22931767bb835132c04571b66d5434020fd4147f&scene=21#wechat_redirect)》。



## 5.5 其他需求...

本文写到这里，上述一、二、三、四、五其实都不是重点，base-service层通过各种各样的奇技淫巧，能够解决db水平切分后的数据访问问题，只不过：

- base-service层的复杂度提高了
- 数据的获取效率降低了

 

当需要**进行db水平切分的base-service越来越多以后**，此时分层架构会变成下面这个样子：

![image-20190707201204339](http://ww1.sinaimg.cn/large/006tNc79ly1g4rjfrbfszj30d503fgmc.jpg)

底层的**复杂性会扩散**到各个base-service，所有的base-service都要关注：

- partition key路由
- 非partition key查询，先mapping，再路由
- 先全库，再合并
- 先分析，再按需路由
- 夸库分页处理
- …

这个架构图是不是看上去很别扭？**如何让数据的获取更加高效快捷呢？**

数据库中间件的引入，势在必行。

![image-20190707201244265](http://ww1.sinaimg.cn/large/006tNc79ly1g4rjfrp1k3j30at04ujs6.jpg)

这是“基于服务端”的数据库中间件架构图：

- base-service层，就像访问db一样，访问db-proxy，高效获取数据
- 所有底层的复杂性，都屏蔽在db-proxy这一层

![image-20190707201301184](http://ww4.sinaimg.cn/large/006tNc79ly1g4rjfsjidfj30d503fgmc.jpg)

这是“基于客户端”的数据库中间件架构图：

- base-service层，通过db-proxy.jar，高效获取数据
- 所有底层的复杂性，都屏蔽在db-proxy.jar这一层

![image-20190707201315950](http://ww4.sinaimg.cn/large/006tNc79ly1g4rjful5rqj309307l0u1.jpg)

**结论**：

**当**数据库水平切分，base-service层获取db数据过于复杂，成为通用痛点**的时候**，就应该抽象出数据库中间件，简化数据获取过程，提高数据获取效率，向上游屏蔽底层的复杂性。

