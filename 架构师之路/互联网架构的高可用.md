# Table of Contents

* [1  什么是高可用](#1--什么是高可用)
* [2  如何保障系统的高可用](#2--如何保障系统的高可用)
* [3  常见的互联网分层架构](#3--常见的互联网分层架构)
* [4  分层高可用架构实践](#4--分层高可用架构实践)
  * [4.1 【客户端层->反向代理层】的高可用](#41-【客户端层-反向代理层】的高可用)
  * [4.2 【反向代理层->站点层】的高可用](#42-【反向代理层-站点层】的高可用)
  * [4.3 【站点层->服务层】的高可用](#43-【站点层-服务层】的高可用)
  * [4.4 【服务层>缓存层】的高可用](#44-【服务层缓存层】的高可用)
  * [4.5 【服务层>数据库层“读”】的高可用](#45-【服务层数据库层读】的高可用)
  * [4.6 【服务层>数据库层“写”】的高可用](#46-【服务层数据库层写】的高可用)
* [5  总结](#5--总结)
* [6  高可用案例分享](#6--高可用案例分享)
  * [6.1 客户端层—>反向代理层高可用](#61-客户端层反向代理层高可用)
  * [6.2 反向代理层—>WebServer层高可用](#62-反向代理层webserver层高可用)
  * [6.3 WebServer层—>数据库层写高可用](#63-webserver层数据库层写高可用)
  * [6.4 WebServer层—>数据库层读高可用](#64-webserver层数据库层读高可用)
  * [6.5 WebServer层—>Cache层高可用](#65-webserver层cache层高可用)


# 1  什么是高可用

**高可用HA**（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。

假设系统一直能够提供服务，我们说系统的可用性是100%。

如果系统每运行100个时间单位，会有1个时间单位无法提供服务，我们说系统的可用性是99%。

很多公司的高可用目标是4个9，也就是99.99%，这就意味着，系统的年停机时间为8.76个小时。

百度的搜索首页，是业内公认高可用保障非常出色的系统，甚至人们会通过www.baidu.com 能不能访问来判断“网络的连通性”，百度高可用的服务让人留下啦“网络通畅，百度就能访问”，“百度打不开，应该是网络连不上”的印象，这其实是对百度HA最高的褒奖。



# 2  如何保障系统的高可用

我们都知道，单点是系统高可用的大敌，单点往往是系统高可用最大的风险和敌人，应该尽量在系统设计的过程中避免单点。方法论上，高可用保证的原则是“集群化”，或者叫“冗余”：只有一个单点，挂了服务会受影响；如果有冗余备份，挂了还有其他backup能够顶上。

**保证系统高可用，架构设计的核心准则是：冗余。**

有了冗余之后，还不够，每次出现故障需要人工介入恢复势必会增加系统的不可服务实践。所以，又往往是通过“自动故障转移”来实现系统的高可用。

接下来我们看下典型互联网架构中，如何通过**冗余+自动故障转移**来保证系统的高可用特性。



# 3  常见的互联网分层架构

![image-20190708172508923](http://ww4.sinaimg.cn/large/006tNc79ly1g4skqooy71j30ck0a2tbd.jpg)

常见互联网分布式架构如上，分为：

（1）**客户端层**：典型调用方是浏览器browser或者手机应用APP

（2）**反向代理层**：系统入口，反向代理

（3）**站点应用层**：实现核心应用逻辑，返回html或者json

（4）**服务层**：如果实现了服务化，就有这一层

（5）**数据**-**缓存层**：缓存加速访问存储

（6）**数据**-**数据库层**：数据库固化数据存储

整个系统的高可用，又是通过每一层的**冗余**+**自动故障转移**来综合实现的。



# 4  分层高可用架构实践

## 4.1 【客户端层->反向代理层】的高可用

![image-20190708172842979](http://ww2.sinaimg.cn/large/006tNc79ly1g4skqpj4svj30an03dgm8.jpg)

【客户端层】到【反向代理层】的**高可用**，是通过反向代理层的冗余来实现的。以nginx为例：有两台nginx，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是keepalived存活探测，相同virtual IP提供服务。

![image-20190708172857138](http://ww3.sinaimg.cn/large/006tNc79ly1g4skqqhybzj30ab03ljrw.jpg)

**自动故障转移**：当nginx挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-nginx，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的。



## 4.2 【反向代理层->站点层】的高可用

![image-20190708172935443](http://ww1.sinaimg.cn/large/006tNc79ly1g4skqr1uuxj307m04gjs1.jpg)

【反向代理层】到【站点层】的**高可用**，是通过站点层的冗余来实现的。假设反向代理层是nginx，nginx.conf里能够配置多个web后端，并且nginx能够探测到多个后端的存活性。

![image-20190708172953144](http://ww4.sinaimg.cn/large/006tNc79ly1g4skqrem62j308o04uaap.jpg)

**自动故障转移**：当web-server挂了的时候，nginx能够探测到，会自动的进行故障转移，将流量自动迁移到其他的web-server，整个过程由nginx自动完成，对调用方是透明的。



## 4.3 【站点层->服务层】的高可用

![image-20190708173053487](http://ww4.sinaimg.cn/large/006tNc79ly1g4skqrwjoyj307405o752.jpg)

【站点层】到【服务层】的**高可用**，是通过服务层的冗余来实现的。“服务连接池”会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。

![image-20190708173105758](http://ww3.sinaimg.cn/large/006tNc79ly1g4skqsw98vj306p05odgh.jpg)

**自动故障转移**：当service挂了的时候，service-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的service，整个过程由连接池自动完成，对调用方是透明的（所以说RPC-client中的服务连接池是很重要的基础组件）。



## 4.4 【服务层>缓存层】的高可用

![image-20190708173202468](http://ww4.sinaimg.cn/large/006tNc79ly1g4skqtbloij307005daan.jpg)

【服务层】到【缓存层】的高可用，是通过缓存数据的冗余来实现的。

缓存层的数据冗余又有几种方式：第一种是利用客户端的封装，service对cache进行双读或者双写。

![image-20190708173216492](http://ww1.sinaimg.cn/large/006tNc79ly1g4skqtpvpzj30au07j3zl.jpg)

缓存层也可以通过支持主从同步的缓存集群来解决缓存层的**高可用**问题。

以redis为例，redis天然支持主从同步，redis官方也有sentinel哨兵机制，来做redis的存活性检测。

![image-20190708173231147](http://ww1.sinaimg.cn/large/006tNc79ly1g4skqu8io3j30ce076my8.jpg)

**自动故障转移**：当redis主挂了的时候，sentinel能够探测到，会通知调用方访问新的redis，整个过程由sentinel和redis集群配合完成，对调用方是透明的。

 

说完缓存的高可用，这里要多说一句，业务对缓存并不一定有“高可用”要求，更多的对缓存的使用场景，是用来“加速数据访问”：把一部分数据放到缓存里，如果缓存挂了或者缓存没有命中，是可以去后端的数据库中再取数据的。

这类允许“cache miss”的业务场景，缓存架构的建议是：

![image-20190708173250067](http://ww2.sinaimg.cn/large/006tNc79ly1g4skqv926nj309z06fdgv.jpg)

将kv缓存封装成服务集群，上游设置一个代理（代理可以用集群冗余的方式保证高可用），代理的后端根据缓存访问的key水平切分成若干个实例，每个实例的访问并不做高可用。

![image-20190708173339760](http://ww4.sinaimg.cn/large/006tNc79ly1g4skqw4ssoj30bs06sq41.jpg)

**缓存实例挂了屏蔽**：当有水平切分的实例挂掉时，代理层直接返回cache miss，此时缓存挂掉对调用方也是透明的。key水平切分实例减少，不建议做re-hash，这样容易引发缓存数据的不一致。



## 4.5 【服务层>数据库层“读”】的高可用

![image-20190708173752675](http://ww2.sinaimg.cn/large/006tNc79ly1g4skqx59joj308606kmya.jpg)

【服务层】到【数据库读】的**高可用**，是通过读库的冗余来实现的。

既然冗余了读库，一般来说就至少有2个从库，“数据库连接池”会建立与读库多个连接，每次请求会路由到这些读库。

![image-20190708173809844](http://ww4.sinaimg.cn/large/006tNc79ly1g4skqxh96lj308k06emy0.jpg)

**自动故障转移**：当读库挂了的时候，db-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的读库，整个过程由连接池自动完成，对调用方是透明的（所以说DAO中的数据库连接池是很重要的基础组件）。



## 4.6 【服务层>数据库层“写”】的高可用

![image-20190708173901221](http://ww1.sinaimg.cn/large/006tNc79ly1g4skqxzkiuj306x03g0tc.jpg)

【服务层】到【数据库写】的**高可用**，是通过写库的冗余来实现的。

以mysql为例，可以设置两个mysql双主同步，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是keepalived存活探测，相同virtual IP提供服务。

![image-20190708173914229](http://ww1.sinaimg.cn/large/006tNc79ly1g4skqyenwij307i03o0t6.jpg)

**自动故障转移**：当写库挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-db-master，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的。



# 5  总结

高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。

方法论上，高可用是通过**冗余**+**自动故障转移**来实现的。

整个互联网分层系统架构的高可用，又是通过每一层的**冗余**+**自动故障转移**来综合实现的，具体的：

（1）【客户端层】到【反向代理层】的高可用，是通过反向代理层的冗余实现的，**常见实践是keepalived + virtual IP自动故障转移**

（2）【反向代理层】到【站点层】的高可用，是通过站点层的冗余实现的，**常见实践是nginx与web-server之间的存活性探测与自动故障转移**

（3）【站点层】到【服务层】的高可用，是通过服务层的冗余实现的，**常见实践是通过service-connection-pool来保证自动故障转移**

（4）【服务层】到【缓存层】的高可用，是通过缓存数据的冗余实现的，常见实践是缓存客户端双读双写，或者利用缓存集群的主从数据同步与sentinel保活与自动故障转移（**redis主从+哨兵监控**）；更多的业务场景，对缓存没有高可用要求，可以使用缓存服务化来对调用方屏蔽底层复杂性

（5）【服务层】到【数据库“读”】的高可用，是通过读库的冗余实现的，**常见实践是通过db-connection-pool来保证自动故障转移**

（6）【服务层】到【数据库“写”】的高可用，是通过写库的冗余实现的，**常见实践是keepalived + virtual IP自动故障转移**



# 6  高可用案例分享

## 6.1 客户端层—>反向代理层高可用

通过反向代理层冗余来实现。以nginx为例，如下架构图所示：两台nginx，一台提供服务，另一台冗余以保证高可用，客户端连接VIP:Nginx的代理端口

![image-20190708174334072](http://ww3.sinaimg.cn/large/006tNc79ly1g4skqzexnqj30j1095gqe.jpg)

- 当Host 1.2.3.8机器异常时，因为是冗余机器，业务不影响；

- 当Host 1.2.3.7机器异常时

- - Nginx异常时，keepalived检查失败后降权，vip漂移到另一台keepalived机器
  - 当keepalived挂掉时，vip立即漂移到另外一台keepalived机器

- 重要说明

- - 机器冗余，资源开销会大一倍，空闲一台机器
  - 推荐直接用云服务商-负载均衡服务(比如ucloud的ULB)，省自己配置keepalived并能省去冗余的Nginx实例



## 6.2 反向代理层—>WebServer层高可用

通过WebServer的冗余来实现的，以Nginx为例，Nginx能够探测到多个后端的存活性，自动剔除失败的节点，架构如下所示；

![image-20190708174418545](http://ww3.sinaimg.cn/large/006tNc79ly1g4skr0e1m7j30j805udiw.jpg)

web-server挂了时，nginx能探测到，其自动的进行故障转移，将流量自动迁移到其他的web-server，整个过程由nginx自动完成，对调用方是透明的。



## 6.3 WebServer层—>数据库层写高可用

采用keepalived+haproxy+双主mysql模式，保障mysql的高可用，架构如下图所示：

![image-20190708174530493](http://ww1.sinaimg.cn/large/006tNc79ly1g4skr0w7a4j30a009a76e.jpg)

- 双主mysql，当一台mysql挂掉时，haproxy使用另外一个mysql提供服务
- 当haproxy故障时，keepalived检查失败后降权，vip漂移到另外一台keepalived机器，使用备用的haproxy实例
- 当keepalived挂掉时，vip立即漂移到另外一台keepalived机



## 6.4 WebServer层—>数据库层读高可用

通过数据库搭建一主多从架构，并编写数据库连接池来实现，架构如下：

![image-20190708174607980](http://ww2.sinaimg.cn/large/006tNc79ly1g4skr17i68j30j308b41r.jpg)

- db-connection-pool与多个读库建立连接，每次请求采用一定的负载均衡策略路由到某读库。
- 当读库挂了的时候，db-connection-pool探测到，并自动的进行故障转移，将流量迁移到其他的读库



## 6.5 WebServer层—>Cache层高可用

Redis通过Sentinel（哨兵）实现高可用，改造RedisClient的连接，架构如下

![image-20190708174653711](http://ww1.sinaimg.cn/large/006tNc79ly1g4skr1ymvej30iz07rq6e.jpg)

- RedisSlave节点异常，不会对服务造成影响

- RedisMaster节点异常时

- - Sentinel集群监控到异常，进行故障转移，提升Slave为Master节点
  - RedisClient连接池检测异常，重新获取master节点，并迁移连接到新的节点 

